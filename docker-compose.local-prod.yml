# GPUBROKER - Local Production-Like Stack
# ===========================================
# Production-grade configuration for local development
# TOTAL MEMORY LIMIT: 10GB (configurable via CLUSTER_MEMORY_LIMIT)
# PERSISTENT VOLUMES: All data is persisted
# RESTART POLICIES: Always restart on failure
# HEALTH CHECKS: All services have health checks
# ===========================================

services:
  # ============================================
  # SECRET MANAGEMENT - HashiCorp Vault
  # Memory: 384MB | Priority: Critical
  # ============================================
  vault:
    image: hashicorp/vault:1.15
    container_name: gpubroker-vault
    hostname: vault
    restart: always
    ports:
      - "${PORT_VAULT:-28005}:8200"
    environment:
      VAULT_ADDR: "http://0.0.0.0:8200"
      VAULT_API_ADDR: "http://0.0.0.0:8200"
      VAULT_LOG_LEVEL: "info"
    cap_add:
      - IPC_LOCK
    volumes:
      - vault_data:/vault/data
      - vault_logs:/vault/logs
      - ./infrastructure/vault/config:/vault/config:ro
      - ./infrastructure/vault/scripts:/vault/scripts:ro
    command: server -config=/vault/config/vault.hcl
    healthcheck:
      test: [ "CMD", "vault", "status", "-address=http://127.0.0.1:8200" ]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 384M
        reservations:
          memory: 192M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - gpubroker-network

  # ============================================
  # PostgreSQL Database
  # Memory: 1GB | Priority: Critical
  # ============================================
  postgres:
    image: postgres:15-alpine
    container_name: gpubroker-postgres
    hostname: postgres
    restart: always
    ports:
      - "${PORT_POSTGRES:-28001}:5432"
    environment:
      POSTGRES_USER: gpubroker
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-gpubroker_secure_local}
      POSTGRES_DB: gpubroker
      PGDATA: /var/lib/postgresql/data/pgdata
      # Production-like settings
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_backups:/backups
      - ./database/init:/docker-entrypoint-initdb.d:ro
      - ./infrastructure/postgres/postgresql.conf:/etc/postgresql/postgresql.conf:ro
    command: >
      postgres  -c shared_buffers=256MB  -c effective_cache_size=512MB  -c maintenance_work_mem=64MB  -c checkpoint_completion_target=0.9  -c wal_buffers=16MB  -c random_page_cost=1.1  -c log_statement=all  -c log_min_duration_statement=1000
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U gpubroker -d gpubroker" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    networks:
      - gpubroker-network

  # ============================================
  # Redis Cache & Sessions
  # Memory: 384MB | Priority: Critical
  # ============================================
  redis:
    image: redis:7-alpine
    container_name: gpubroker-redis
    hostname: redis
    restart: always
    ports:
      - "${PORT_REDIS:-28004}:6379"
    command: >
      redis-server --appendonly yes --appendfsync everysec --maxmemory 256mb --maxmemory-policy allkeys-lru --save 900 1 --save 300 10 --save 60 10000 --loglevel notice --tcp-keepalive 300 --timeout 0
    volumes:
      - redis_data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 384M
        reservations:
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - gpubroker-network

  # ============================================
  # Zookeeper (Kafka Dependency)
  # Memory: 512MB | Priority: High
  # ============================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: gpubroker-zookeeper
    hostname: zookeeper
    restart: always
    ports:
      - "${PORT_ZOOKEEPER:-28008}:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 5
      ZOOKEEPER_INIT_LIMIT: 10
      KAFKA_HEAP_OPTS: "-Xmx384m -Xms256m"
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    healthcheck:
      test: [ "CMD-SHELL", "echo srvr | nc localhost 2181 || exit 1" ]
      interval: 20s
      timeout: 10s
      retries: 10
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - gpubroker-network

  # ============================================
  # Apache Kafka (Event Streaming)
  # Memory: 1GB | Priority: High
  # ============================================
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: gpubroker-kafka
    hostname: kafka
    restart: always
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "${PORT_KAFKA:-28007}:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:${PORT_KAFKA:-28007}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      KAFKA_LOG_SEGMENT_BYTES: 536870912
      KAFKA_HEAP_OPTS: "-Xmx768m -Xms512m"
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: [ "CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    networks:
      - gpubroker-network

  # ============================================
  # ClickHouse Analytics Database
  # Memory: 1.5GB | Priority: Medium
  # ============================================
  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    container_name: gpubroker-clickhouse
    hostname: clickhouse
    restart: always
    ports:
      - "${PORT_CLICKHOUSE_HTTP:-28002}:8123"
      - "${PORT_CLICKHOUSE_NATIVE:-28003}:9000"
    environment:
      CLICKHOUSE_DB: gpubroker_analytics
      CLICKHOUSE_USER: gpubroker
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-clickhouse_secure_local}
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_logs:/var/log/clickhouse-server
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://localhost:8123/ping" ]
      interval: 20s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1536M
        reservations:
          memory: 768M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
    networks:
      - gpubroker-network

  # ============================================
  # Django Backend (Main Application)
  # Memory: 1.5GB | Priority: Critical
  # ============================================
  django:
    build:
      context: ./backend/gpubroker
      dockerfile: Dockerfile
    container_name: gpubroker-django
    hostname: django
    restart: always
    ports:
      - "${PORT_DJANGO:-28080}:8000"
    environment:
      # Django Settings
      DJANGO_SETTINGS_MODULE: config.settings.sandbox
      SECRET_KEY: ${DJANGO_SECRET_KEY:-django-local-prod-secure-key-change-in-real-prod}
      DEBUG: "False"
      ALLOWED_HOSTS: localhost,127.0.0.1,django,gpubroker.local

      # Database
      DATABASE_URL: postgresql://gpubroker:${POSTGRES_PASSWORD:-gpubroker_secure_local}@postgres:5432/gpubroker

      # Redis
      REDIS_URL: redis://redis:6379/0

      # Kafka
      KAFKA_BROKERS: kafka:9092

      # ClickHouse
      CLICKHOUSE_URL: http://gpubroker:${CLICKHOUSE_PASSWORD:-clickhouse_secure_local}@clickhouse:8123/gpubroker_analytics

      # Vault
      VAULT_ADDR: http://vault:8200
      VAULT_ROLE_ID: ${VAULT_ROLE_ID:-}
      VAULT_SECRET_ID: ${VAULT_SECRET_ID:-}

      # CORS
      CORS_ALLOWED_ORIGINS: http://localhost:3000,http://localhost:${PORT_FRONTEND:-28030},http://localhost:${PORT_NGINX:-80}

      # Agent / AI
      SOMA_AGENT_BASE: ${SOMA_AGENT_BASE:-http://localhost:8080}

      # PayPal
      PAYPAL_CLIENT_ID_SANDBOX: ${PAYPAL_CLIENT_ID_SANDBOX:-}
      PAYPAL_CLIENT_SECRET_SANDBOX: ${PAYPAL_CLIENT_SECRET_SANDBOX:-}
      PAYPAL_CLIENT_ID_LIVE: ${PAYPAL_CLIENT_ID_LIVE:-}
      PAYPAL_CLIENT_SECRET_LIVE: ${PAYPAL_CLIENT_SECRET_LIVE:-}

      # JWT Keys
      JWT_PRIVATE_KEY: ${JWT_PRIVATE_KEY:-}
      JWT_PUBLIC_KEY: ${JWT_PUBLIC_KEY:-}

      # Logging
      LOG_LEVEL: INFO
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      vault:
        condition: service_started
    volumes:
      - ./backend/gpubroker:/app
      - ./backend/shared:/app/shared:ro
      - django_static:/app/staticfiles
      - django_media:/app/media
    command: >
      sh -c "
        python manage.py migrate --noinput &&
        python manage.py collectstatic --noinput &&
        daphne -b 0.0.0.0 -p 8000 config.asgi:application
      "
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/api/v2/admin/public/health" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1536M
        reservations:
          memory: 768M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    networks:
      - gpubroker-network

  # ============================================
  # Next.js Frontend
  # Memory: 1GB | Priority: High
  # ============================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: gpubroker-frontend
    hostname: frontend
    restart: always
    ports:
      - "${PORT_FRONTEND:-28030}:3000"
    environment:
      NODE_ENV: production
      NEXT_PUBLIC_API_URL: http://localhost:${PORT_NGINX:-80}/api/v2
      NEXT_PUBLIC_WS_URL: ws://localhost:${PORT_NGINX:-80}/ws
      NEXT_PUBLIC_PROVIDER_API_URL: http://localhost:${PORT_NGINX:-80}/api/v2/providers
      NEXT_PUBLIC_KPI_API_URL: http://localhost:${PORT_NGINX:-80}/api/v2/kpi
      NEXT_PUBLIC_AI_API_URL: http://localhost:${PORT_NGINX:-80}/api/v2/ai
    depends_on:
      - django
    volumes:
      - ./frontend:/app
      - frontend_node_modules:/app/node_modules
      - frontend_next:/app/.next
    command: npm run dev
    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://localhost:3000" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - gpubroker-network

  # ============================================
  # Nginx Reverse Proxy
  # Memory: 128MB | Priority: Critical
  # ============================================
  nginx:
    image: nginx:1.25-alpine
    container_name: gpubroker-nginx
    hostname: nginx
    restart: always
    ports:
      - "${PORT_NGINX:-80}:80"
      - "${PORT_NGINX_SSL:-443}:443"
    volumes:
      - ./infrastructure/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - django_static:/var/www/static:ro
      - django_media:/var/www/media:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      django:
        condition: service_healthy
      frontend:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "nginx", "-t" ]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"
    networks:
      - gpubroker-network

  # ============================================
  # Prometheus Metrics
  # Memory: 512MB | Priority: Medium
  # ============================================
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: gpubroker-prometheus
    hostname: prometheus
    restart: always
    ports:
      - "${PORT_PROMETHEUS:-28031}:9090"
    volumes:
      - ./infrastructure/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=15d"
      - "--storage.tsdb.retention.size=2GB"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--web.enable-lifecycle"
      - "--web.enable-admin-api"
    healthcheck:
      test: [ "CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - gpubroker-network

  # ============================================
  # Grafana Dashboards
  # Memory: 384MB | Priority: Medium
  # ============================================
  grafana:
    image: grafana/grafana:10.2.0
    container_name: gpubroker-grafana
    hostname: grafana
    restart: always
    ports:
      - "${PORT_GRAFANA:-28032}:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin_local_secure}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_ROOT_URL: http://localhost:${PORT_GRAFANA:-28032}
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./infrastructure/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    healthcheck:
      test: [ "CMD-SHELL", "wget -q --spider http://localhost:3000/api/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 384M
        reservations:
          memory: 192M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - gpubroker-network

# ============================================
# PERSISTENT VOLUMES
# ============================================
volumes:
  # Critical Data
  postgres_data:
    driver: local
    name: gpubroker_postgres_data
  postgres_backups:
    driver: local
    name: gpubroker_postgres_backups
  redis_data:
    driver: local
    name: gpubroker_redis_data
  clickhouse_data:
    driver: local
    name: gpubroker_clickhouse_data
  clickhouse_logs:
    driver: local
    name: gpubroker_clickhouse_logs
  kafka_data:
    driver: local
    name: gpubroker_kafka_data
  zookeeper_data:
    driver: local
    name: gpubroker_zookeeper_data
  zookeeper_logs:
    driver: local
    name: gpubroker_zookeeper_logs

  # Secrets
  vault_data:
    driver: local
    name: gpubroker_vault_data
  vault_logs:
    driver: local
    name: gpubroker_vault_logs

  # Application
  django_static:
    driver: local
    name: gpubroker_django_static
  django_media:
    driver: local
    name: gpubroker_django_media
  frontend_node_modules:
    driver: local
    name: gpubroker_frontend_node_modules
  frontend_next:
    driver: local
    name: gpubroker_frontend_next

  # Observability
  prometheus_data:
    driver: local
    name: gpubroker_prometheus_data
  grafana_data:
    driver: local
    name: gpubroker_grafana_data
  nginx_logs:
    driver: local
    name: gpubroker_nginx_logs

# ============================================
# NETWORK CONFIGURATION
# ============================================
networks:
  gpubroker-network:
    driver: bridge
    name: gpubroker-net
